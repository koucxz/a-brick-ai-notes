# 2026年了，还没用AI写代码？三年亲历+未来大胆预测

2022年11月30日，ChatGPT发布。

作为一个从2020年就开始关注AI发展的前端开发者，这三年我见证了从GPT-3的惊艳，到Stable Diffusion的爆火，再到ChatGPT的现象级传播。

但真正改变我工作方式的，是2024-2025年发生的这些变化——特别是Claude 4.5的发布，让我从"觉得不过如此"到"必须更懂AI"。

这篇文章，我想结合自己的开发经历，聊聊AIGC这三年到底经历了什么。

## 一、那个让全世界沸腾的5天

5天，100万用户。两个月，1亿用户。

这个增长速度打破了互联网历史上所有产品的记录。Instagram用了2.5个月才到100万，Facebook用了10个月。

不只是科技圈的人在关注，连做传统行业的朋友都开始问我："这个ChatGPT到底是什么？我们公司要不要也搞点AI？"

我从2020年GPT-3发布就开始关注这个方向，当时它还只是个API，门槛太高，普通人根本接触不到。ChatGPT把这个门槛降到了零——任何人都可以直接对话，直接体验AI的能力。

那段时间全球经济挺低迷的，疫情刚过，大家都在找新的增长点。ChatGPT的出现让很多人意识到：互联网还没到下半场，还有很多事情可以做。

### OpenAI的崛起之路

OpenAI的故事其实要从更早说起：

- **2017年6月**：Google发布《Attention Is All You Need》论文，提出Transformer架构
- **2018年6月**：GPT-1发布，1.17亿参数
- **2019年2月**：GPT-2发布，15亿参数（因担心滥用，最初只发布了小版本）
- **2020年6月**：GPT-3发布，1750亿参数，震惊业界
- **2022年11月30日**：ChatGPT发布，基于GPT-3.5，免费开放给所有人
- **2023年3月**：GPT-4发布，多模态能力初现
- **2023年9月**：GPT-4V（Vision）发布，真正的多模态模型
- **2025年初**：GPT-4.5发布，推理能力和上下文长度大幅提升
- **2025年8月**：GPT-5发布，具备更强的Agent能力和工具使用能力

**为什么Transformer论文2017年就发了，AI到2022年才火？**

这是很多人的疑问。核心原因有三个：

1. **算力的积累**：Transformer架构需要海量算力。2017年的GPU算力和成本，根本支撑不了GPT-3这种1750亿参数的模型训练。英伟达A100/H100的普及、云计算成本的下降，是技术落地的前提。

2. **规模定律的验证**：OpenAI在2020年发表了Scaling Laws论文，证明了"模型越大、数据越多、效果越好"这个规律。在此之前，没人确定堆参数是否有意义。GPT-3的成功验证了这条路是对的。

3. **产品化的临门一脚**：GPT-3虽然强，但只是API，普通人用不了。ChatGPT的关键创新是把它包装成了对话产品，任何人都能直接体验。技术到产品的转化，往往需要这样的"最后一步"。

简单说：**论文是种子，算力是土壤，产品是收获**。2017年种下的种子，花了5年才等到合适的土壤和收获的时机。

OpenAI的成功不仅仅是技术上的，更是产品和商业模式上的。他们用ChatGPT这个产品，把复杂的技术变成了人人都能用的工具。

## 二、Claude：从"不过如此"到"离不开"

在Claude 4.5发布之前，我对它的真实感受就是"不过如此"。

2023年3月Claude 1刚发布时，我觉得它虽然强调安全性和有用性，但相比ChatGPT并没有给我带来特别的惊喜。2023年7月Claude 2支持100K上下文确实让人眼前一亮，但实际使用中还是经常遇到"人工智障"的时刻——理解不了我的需求，回答总是差那么一点意思。

即使到了2024年3月Claude 3系列发布，包含Haiku、Sonnet、Opus三个版本，我也只是把它当作"又一个大模型"。

真正让我态度转变的，是Claude 4.5的发布。

举个具体的例子。我们项目是一个微信小程序，用的是自定义装饰器架构（SuperPage + 依赖注入 + RxJS），这套架构比较非主流，之前的AI工具基本理解不了。有一次我需要重构一个商品列表页，涉及到RxJS的订阅管理、Lock装饰器的使用、以及和后端Swagger API的对接。之前用Claude 3，它连`takeUntil(this.unloadObservable)`这种项目特有的模式都搞不明白，给出的建议经常是错的。

但Claude 4.5不一样。它不仅理解了整个装饰器体系，还指出了我一个潜在的内存泄漏——有个订阅忘了加`takeUntil`。这种对项目上下文的理解深度，是之前完全做不到的。

Anthropic的发展轨迹：

- 2023年3月：Claude 1发布，强调安全性和有用性
- 2023年7月：Claude 2发布，支持100K上下文
- 2024年3月：Claude 3系列发布（Haiku / Sonnet / Opus）
- 2024年6月：Claude Sonnet 3.5发布，在代码理解和多模态方面超越GPT-4
- 2025年11月24日：Claude Opus 4.5发布，编码能力带来质的飞跃

Claude Opus 4.5 的实际表现（官方数据）：

| 基准测试 | Claude Opus 4.5 | GPT-4o | Claude 3.5 Sonnet |
|---------|-----------------|--------|-------------------|
| SWE-bench Verified | 72.0% | 38.0% | 49.0% |
| HumanEval | 92.0% | 90.2% | 88.0% |
| GPQA Diamond | 65.0% | 53.6% | 59.4% |
| MATH | 83.6% | 76.6% | 78.3% |

SWE-bench 衡量的是真实软件工程任务的完成能力，72%的得分几乎是GPT-4o的两倍。这个数据和我的体感是一致的——在处理真实项目代码时，差距确实很明显。

### Claude Code：我的日常开发搭档

2024年Anthropic推出Claude Code时，我觉得它"有点意思，但可有可无"。

最初使用时，它能理解代码库结构、执行重构任务，但总觉得差一点火候——有时候理解不了我的真实意图，给出的建议不够精准。

Claude 4.5发布后，体验完全不同了。举个真实场景：我们项目里有一个Vue 3的H5页面，用Vant组件库 + Pinia做状态管理。有一次我需要给一个商品搜索页加一个下拉筛选功能，我只是用自然语言描述了需求，Claude Code直接生成了符合我们项目规范的`<script setup lang="ts">`代码，连Vant组件的用法和Less样式的写法都是对的。以前这种活至少要写半天，现在十几分钟就搞定了。

它已经从一个"有点意思的工具"变成了我每天都在用的开发搭档。

## 三、疯狂的上半场：钱都去哪了？

2023年上半年，用"疯狂"形容一点都不过分。

| 时间 | 生成式AI融资额 |
|------|---------------|
| 2021年全年 | 30-40亿美金 |
| 2022年全年 | 30-40亿美金 |
| 2023年Q1 | 110亿美金 |
| 2023年上半年 | 150亿美金 |
| 2024年全年 | 约330亿美金 |

2023年上半年的融资额，是过去两年总和的两倍还多。其中OpenAI拿走了大头（微软投的100亿），但即便刨除OpenAI，其他公司的融资额也在暴涨。到了2024年，Anthropic又拿到了亚马逊的40亿美金投资，整个赛道的资金规模继续膨胀。

那段时间，所有投资人都在找AI项目。不管你之前做什么的，只要跟AI沾边，都有人愿意聊。王慧文、百川智能这些明星项目，融资消息一个接一个。

### 开发者工具的爆发

2023年下半年到2024年，AI开发者工具开始大量涌现：

- GitHub Copilot X：从代码补全升级为整个开发流程的AI助手
- Cursor：专门为AI编程设计的IDE，支持自然语言编程
- Claude Code：Anthropic推出的终端AI助手，深度集成到开发工作流中
- CodeWhisperer：AWS推出的AI编程工具

我自己的体验是，2023年初用Copilot写代码，它只能补全一些简单的函数。到了2024年用Cursor和Claude Code，它们已经能理解整个项目的上下文，帮我做跨文件的重构。这个进步速度是肉眼可见的。

## 四、转折点：访问量下降了？

到了2023年7、8月份，画风突然变了。

9月8日，SimilarWeb发布数据：ChatGPT的访问量连续三个月下滑，下降了3.2%。很多媒体开始唱衰："AIGC泡沫要破了。"

但仔细看数据会发现：
- 即便下降，月访问量还有14亿次——全网有几个产品能做到？
- 下降的主要是免费用户，真正付费的用户在增长
- 大量账号被封，中国等地区访问受限
- OpenAI开始赚钱了——API调用和GPT-4订阅才是核心

这个"下降"，其实是正常的商业化过程。泡沫在挤，但核心价值还在。

## 五、2024：真正的转折之年

如果说2023年是AIGC的"狂热期"，那么2024年就是"务实期"的开始。

### 1. 多模态成为标配

2023年9月GPT-4V发布，可以直接理解图片。但真正让多模态普及的是2024年：

- Gemini 1.5 Pro：支持1M token上下文，能同时处理文本、图像、音频、视频
- Claude 3.5 Sonnet：在代码理解和多模态推理上表现优异
- 开源多模态模型：LLaVA-1.6、Qwen-VL等让多模态能力不再遥不可及

我在实际项目中感受很深。以前做商品图片的信息提取，要调专门的OCR API，写一堆解析逻辑。现在直接把图片扔给大模型，一句prompt就能拿到结构化数据。这不只是方便，而是开发范式的改变。

### 2. 长上下文的突破

2024年初，Claude 3支持了200K的上下文，Gemini 1.5达到了1M。

这对我的工作影响很大。我们的小程序项目有几十个页面文件，以前做代码review只能一个文件一个文件地看。现在能一次性把整个项目的核心代码都喂给Claude，让它帮我找跨文件的问题——比如某个服务在A页面和B页面的调用方式不一致，这种问题以前很难发现。

### 3. Agent和工具调用的成熟

2024年是Agent真正开始落地的一年：

- AutoGen框架：微软推出的多Agent协作框架变得成熟
- LangChain/LlamaIndex：工具调用和RAG的最佳实践逐渐形成
- AI编程助手：GitHub Copilot、Cursor、Claude Code开始支持复杂的开发任务

我自己试过用AI Agent自动化处理Swagger API的生成和类型定义更新。以前每次后端接口变更，我都要手动跑swagger命令、检查类型变化、更新调用代码。现在这套流程基本可以半自动化完成。

### 4. 开源模型的崛起

2024年，开源和闭源模型的差距在快速缩小：

- Llama 3：Meta开源，性能接近GPT-3.5

国产大模型同样值得关注：

| 模型 | 厂商 | 特点 | 适用场景 |
|-----|------|------|---------|
| Kimi | 月之暗面 | 200万token超长上下文 | 长文档分析、论文阅读 |
| Qwen2.5 | 阿里 | 开源、中文能力强 | 企业私有化部署 |
| DeepSeek-V3 | DeepSeek | 开源、性价比极高 | 代码生成、推理任务 |
| GLM-4 | 智谱AI | 多模态、Agent能力强 | 复杂任务编排 |
| 文心一言4.0 | 百度 | 中文理解深、生态完善 | 企业级应用 |

做项目的时候，我会根据场景选择模型：涉及隐私数据的用开源模型自己部署，需要最强能力的用Claude或GPT，简单任务用国产模型控制成本。

### 5. AI编程助手的普及

2024年，GitHub Copilot、Cursor、Claude Code等工具已成为开发者标配。我的开发效率比2023年提升了至少一倍——不是因为AI替我写了所有代码，而是它帮我处理了大量重复性工作（样板代码、类型定义、单元测试），让我能专注在业务逻辑和架构设计上。

## 六、2025：从工具到伙伴

进入2025年，AI的发展又迈上了一个新台阶。如果说2024年AI还是"工具"，那么2025年它开始成为真正的"伙伴"。

### 1. GPT-5和Claude Opus 4.5的发布

2025年，两大巨头都发布了新一代旗舰模型：

GPT-5的主要特点：
- 更强的推理能力，能解决复杂的数学和逻辑问题
- 更好的工具使用能力，能自主调用各种API和工具
- 改进的多模态理解
- 上下文支持达到500K tokens

Claude Opus 4.5的主要特点：
- 200K上下文支持
- 更强的代码理解能力，在HumanEval等基准测试中超越GPT-5
- 改进的Agent能力，能执行更复杂的多步骤任务
- 更好的安全性，减少幻觉

### 2. AI原生应用的爆发

2025年出现了第一批真正的"AI原生应用"——Notion AI、Figma AI、Trae等。它们不是在现有产品上加个AI功能，而是从底层架构就为AI而设计。

### 3. 个人AI助手的兴起：OpenClaw们

2025年另一个值得关注的趋势是个人AI助手的开源化。OpenClaw就是典型代表——一个可以部署在自己设备上的AI助手框架，能连接WhatsApp、Telegram、Slack、微信等所有通讯渠道。

这类产品代表的方向：
- AI助手不再是单独的App，而是连接你所有渠道的统一入口
- 数据留在本地，隐私可控
- 可以自定义行为，而不是被厂商的"安全策略"限制

目前还比较早期，但指向了一个可能的未来：每个人都有自己的"数字分身"。

## 七、写在最后：给技术人的一些建议

从2020年关注AI到现在，快6年了。有人赚到了钱，有人亏得血本无归。有人all in进来，有人黯然离场。

但不管怎样，这一轮AI浪潮跟之前不一样——它不是实验室里的技术，而是真正能改变生产力的工具。泡沫会破，但技术不会倒退。

### 给前端/全栈开发者的具体建议

#### 1. 把AI编程助手用起来，而不是只看新闻

很多人只是在看AI的新闻，看各种模型的发布，但从来没有真正用过。

我的实际工作流是这样的：
- 日常编码用 Cursor 或 Claude Code，让AI处理样板代码和类型定义
- 复杂重构用 Claude Code，它能理解跨文件的依赖关系
- 代码review用 Claude 的长上下文能力，一次性喂入多个文件

一个最简单的 Claude API 调用示例（Python）：

```python
import anthropic

client = anthropic.Anthropic(api_key="your-api-key")

message = client.messages.create(
    model="claude-sonnet-4-20250514",
    max_tokens=1024,
    messages=[{"role": "user", "content": "用一句话解释什么是RAG"}]
)
print(message.content[0].text)
# 输出：RAG（检索增强生成）是一种将外部知识库检索与大语言模型生成相结合的技术，
# 让AI能够基于最新、最相关的信息来回答问题，而不仅仅依赖训练数据。
```

#### 2. 学会用AI处理前端开发中的"脏活"

前端开发中有大量重复性工作特别适合交给AI：

- Swagger API 类型定义生成和更新
- 组件样板代码（Vue的`<script setup>`、React的Hooks模板）
- CSS/Less样式的响应式适配（比如px转vw）
- 国际化文案的批量处理
- 写单元测试（这个AI真的比人快很多）

关键是要学会写好prompt。比如我会在项目里维护一个CLAUDE.md文件，把项目的技术栈、代码规范、路径别名都写清楚，这样AI生成的代码就能直接符合项目规范，不用反复调整。

#### 3. 关注开源模型，但不要为了开源而开源

2025年开源模型已经足够好用了。Ollama、LM Studio等工具让本地部署变得很简单。但要根据场景选择：

- 涉及公司敏感数据 → 开源模型本地部署
- 需要最强代码能力 → Claude 或 GPT
- 简单的文本处理 → 国产模型（成本低）

不要为了省钱在所有场景都用开源模型，也不要为了追求最强在所有场景都用闭源模型。

#### 4. 找到AI和你专业领域的结合点

大模型是基础设施，真正的机会在应用层。比如我做前端开发，就在探索这些方向：

- 用AI辅助UI还原（设计稿 → 代码）
- 用AI做代码迁移（比如从Options API迁移到Composition API）
- 用AI自动化生成API调用层代码

结合自己的专业背景，找到AI能帮你提效的具体环节，比泛泛地"学AI"有用得多。

#### 5. 保持冷静

泡沫期不要盲目跟风，冷静期不要轻易放弃。2023年上半年很多人all in AI创业，现在很多项目都死了。但也有一些项目活下来了，而且活得很好。关键是要有自己的判断，不要被市场情绪左右。

### AI落地的真实挑战

聊了这么多好处，也要说说现实中的坑：

1. 准确性和幻觉
   - 即使是最强的模型，在专业领域仍会"一本正经地胡说八道"
   - 关键业务场景必须有人工审核环节
   - RAG能缓解但无法根治

3. 合规与安全
   - 数据出境问题：敏感数据能否调用海外API？
   - 内容审核：生成内容的合规性谁来负责？
   - 版权争议：AI生成内容的知识产权归属

我的建议是：先在非核心业务试点，验证ROI后再逐步推广。

### 我对未来的一些预测

#### 1. 交互方式：语音会干掉大部分键盘输入

现在我们还在"打字问AI"，但这只是过渡形态。未来2-3年：
- 语音成为主要入口，键盘只用于精确编辑
- AI内置到操作系统，不再是单独的App
- "会说话就会用软件"——菜单和按钮会大幅减少

#### 2. 协议层：MCP和A2A之后，还会出现什么？

Anthropic的MCP解决了AI↔工具，Google的A2A解决了AI↔AI。我预测接下来会出现：

| 协议 | 解决什么问题 |
|-----|------------|
| Memory Protocol | AI如何记住你、跨会话保持上下文、选择性遗忘 |
| AI Permission Model | AI能做什么、不能做什么、谁来审计 |
| Skills Marketplace | AI技能的标准化封装、分发、付费调用 |
| AI Safety Certification | AI行为的安全认证、合规审计、责任追溯 |

#### 4. AI安全：从"对齐"到"可审计"

现在的AI安全主要靠厂商自觉（RLHF、Constitutional AI）。但当AI开始代表你行动、花你的钱，这远远不够：
- AI行为日志会成为强制要求（做了什么、为什么做、谁授权的）
- 会出现第三方AI审计机构，类似财务审计
- "AI保险"可能成为新品类——AI出错造成损失谁来赔？
- 监管会要求AI决策可解释、可追溯、可撤销

### 最后

2020年我开始关注AI的时候，GPT-3刚发布，很多人还在质疑"这东西有什么用"。

2025年，我每天都在用AI写代码、做review、处理文档。Claude 4.5的发布让我意识到，AI已经不是一个可选的工具，而是开发工作流的一部分。

历史总是相似的。每一次技术革命，都会有人说"这次不一样"，也会有人说"这只是泡沫"。

但真正重要的是：你是在观望，还是在参与？

---

### 参考资料

1. [The Complete History of OpenAI Models: From GPT-1 to GPT-5](https://datasciencedojo.com/blog/the-complete-history-of-openai-models/) - GPT 系列完整发展史
2. [GPT Version Timeline: From GPT-1 to GPT-5.2](https://www.timesofai.com/industry-insights/gpt-version-timeline/) - GPT 版本时间线与能力对比
3. [Announcing the Agent2Agent Protocol (A2A)](https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/) - Google 官方博客发布 A2A 协议
4. [Introducing the Model Context Protocol](https://www.anthropic.com/news/model-context-protocol) - Anthropic 官方博客发布 MCP 协议
5. [Introducing Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet) - Claude 3.5 Sonnet 发布公告
6. [OpenClaw GitHub](https://github.com/openclaw/openclaw) - 开源个人 AI 助手框架
7. [DeepSeek-V3 详细介绍](https://zhuanlan.zhihu.com/p/26129262673) - V3 架构与性能解析
8. [Hugging Face 开源模型排行榜](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard) - 开源模型性能对比

